{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантаження даних\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантаження та попередня обробка зображень\n",
    "def get_image_paths(folder, pet_id):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.startswith(pet_id)]\n",
    "\n",
    "def process_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенізація та обробка тексту\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def process_text(text, max_length=128):\n",
    "    tokens = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokens[\"input_ids\"], tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env_mlf/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/env_mlf/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/innasnegurova/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 53.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Модель для зображень\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 256)\n",
    "resnet.eval()\n",
    "\n",
    "def extract_image_features(image_paths):\n",
    "    features_list = []\n",
    "    for image_path in image_paths:\n",
    "        image_tensor = process_image(image_path, image_transform)\n",
    "        with torch.no_grad():\n",
    "            features = resnet(image_tensor)\n",
    "        features_list.append(features.numpy().flatten())\n",
    "    \n",
    "    if features_list:\n",
    "        return np.mean(features_list, axis=0)\n",
    "    else:\n",
    "        return np.zeros(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45cf8c584cf4a098a51c56288c32908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Модель для тексту\n",
    "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "def extract_text_features(text):\n",
    "    input_ids, attention_mask = process_text(text)\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    return output.last_hidden_state[:, 0, :].numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обробка тренувальних даних\n",
    "X_images = np.array([extract_image_features(get_image_paths(\"/mnt/data/images/train\", pet_id)) for pet_id in train_df[\"PetID\"]])\n",
    "X_texts = np.array([extract_text_features(desc) for desc in train_df[\"Description\"].fillna(\"\")])\n",
    "y = train_df[\"AdoptionSpeed\"].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mlf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
